{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663810e-2853-4b6b-adec-658a9e3a5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro-markdown",
   "metadata": {},
   "source": [
    "# Hard Constraints Tutorial for AdaptKAN\n",
    "\n",
    "This tutorial demonstrates how to use **hard constraints** with AdaptKAN. Hard constraints enforce specific function values or derivatives at given points, and they are satisfied **exactly** throughout training.\n",
    "\n",
    "## Use Cases\n",
    "- Boundary conditions for ODEs/PDEs\n",
    "- Known function values at specific points\n",
    "- Smoothness constraints (zero derivative at boundaries)\n",
    "- Physics-informed neural networks (PINNs)\n",
    "\n",
    "## Key Concepts\n",
    "- **Point constraints**: Force `f(x) = y` at specific points\n",
    "- **Derivative constraints**: Force `f'(x) = y` (or higher derivatives)\n",
    "- Constraints work with **Chebyshev basis** only (not B-splines)\n",
    "- Constraints are maintained during **domain adaptation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f9ffc-5115-41ce-9850-274ed0907a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Uncomment to use CPU only\n",
    "# os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from adaptkan.jax.model import AdaptKANJax\n",
    "from adaptkan.jax.fit import fit\n",
    "from adaptkan.jax.losses import mse_loss\n",
    "from adaptkan.jax.viz import plot_model, plot_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1-markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Example: Point Constraints\n",
    "\n",
    "Let's start with a simple example: fitting `sin²(πx)` with boundary constraints `f(0) = f(1) = 0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-constraints",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraints\n",
    "# constraints_in: list of arrays per layer, each (n_constraints, 2) where columns are [x, derivative_order]\n",
    "# constraints_y: list of arrays per layer, each (out_dim, n_constraints) with target values\n",
    "\n",
    "# For a single layer [1] -> [1]:\n",
    "constraints_in = [\n",
    "    jnp.array([\n",
    "        [0.0, 0],  # f(0) = target (derivative_order=0 means value constraint)\n",
    "        [1.0, 0],  # f(1) = target\n",
    "    ])\n",
    "]\n",
    "\n",
    "constraints_y = [\n",
    "    jnp.array([\n",
    "        [0.0, 0.0],  # f(0)=0, f(1)=0\n",
    "    ])\n",
    "]\n",
    "\n",
    "print(\"Constraints:\")\n",
    "print(\"  f(0) = 0\")\n",
    "print(\"  f(1) = 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a constrained AdaptKAN model\n",
    "model, state = eqx.nn.make_with_state(AdaptKANJax)(\n",
    "    width=[1, 1],                     # 1 input -> 1 output\n",
    "    num_grid_intervals=7,\n",
    "    k=7,                              # Chebyshev polynomial degree\n",
    "    basis_type='chebyshev',           # Required for constraints\n",
    "    initialization_range=[0.0, 1.0],\n",
    "    constraints_in=constraints_in,\n",
    "    constraints_y=constraints_y,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Model width: {model.width}\")\n",
    "print(f\"Layer 0 has_constraints: {model.layers[0].has_constraints}\")\n",
    "\n",
    "# Verify constraints are satisfied before training\n",
    "x_test = jnp.array([[0.0], [1.0]])\n",
    "y_pred, _ = model(x_test, state)\n",
    "print(f\"\\nBefore training:\")\n",
    "print(f\"  f(0) = {float(y_pred[0, 0]):.6f} (target: 0)\")\n",
    "print(f\"  f(1) = {float(y_pred[1, 0]):.6f} (target: 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target function: sin²(πx) which naturally satisfies f(0) = f(1) = 0\n",
    "def target_fn(x):\n",
    "    return jnp.sin(jnp.pi * x) ** 2\n",
    "\n",
    "# Generate training data\n",
    "key = jax.random.PRNGKey(0)\n",
    "X_train = jax.random.uniform(key, (200, 1), minval=0.0, maxval=1.0)\n",
    "y_train = target_fn(X_train)\n",
    "\n",
    "# Test data\n",
    "X_test = jnp.linspace(0, 1, 50).reshape(-1, 1)\n",
    "y_test = target_fn(X_test)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the fit function\n",
    "model, state, results = fit(\n",
    "    model,\n",
    "    state,\n",
    "    train_data={\"X\": X_train, \"y\": y_train},\n",
    "    test_data={\"X\": X_test, \"y\": y_test},\n",
    "    loss_fn=mse_loss,\n",
    "    opt=\"Adam\",\n",
    "    learning_rate=0.1,\n",
    "    steps=500,\n",
    "    log_freq=50,\n",
    ")\n",
    "\n",
    "# Verify constraints are STILL satisfied after training\n",
    "y_pred, _ = model(x_test, state)\n",
    "print(f\"\\nAfter training:\")\n",
    "print(f\"  f(0) = {float(y_pred[0, 0]):.6f} (target: 0)\")\n",
    "print(f\"  f(1) = {float(y_pred[1, 0]):.6f} (target: 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Learned vs Target\n",
    "x_plot = jnp.linspace(0, 1, 200).reshape(-1, 1)\n",
    "y_learned, _ = model(x_plot, state)\n",
    "y_target = target_fn(x_plot)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Left: Function comparison\n",
    "axes[0].plot(x_plot, y_target, 'b-', lw=2, label='Target: sin²(πx)')\n",
    "axes[0].plot(x_plot, y_learned, 'g--', lw=2, label='Learned')\n",
    "axes[0].scatter([0, 1], [0, 0], color='red', s=100, zorder=5, label='Constraints')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('f(x)')\n",
    "axes[0].set_title('Point Constraints: f(0) = f(1) = 0')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Training loss\n",
    "axes[1].plot(results['train_loss'], label='Train')\n",
    "axes[1].plot(results['test_loss'], label='Test')\n",
    "axes[1].set_xlabel('Step')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Training Progress')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the layer with constraint markers\n",
    "plot_model(model, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-markdown",
   "metadata": {},
   "source": [
    "## 2. Derivative Constraints\n",
    "\n",
    "Now let's add derivative constraints to create a smooth bump function:\n",
    "- `f(0) = 0, f(1) = 0` (boundary values)\n",
    "- `f'(0) = 0, f'(1) = 0` (zero slope at boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deriv-constraints",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraints with both position (d=0) and derivative (d=1)\n",
    "constraints_in = [\n",
    "    jnp.array([\n",
    "        [0.0, 0],  # f(0) = 0 (value)\n",
    "        [1.0, 0],  # f(1) = 0 (value)\n",
    "        [0.0, 1],  # f'(0) = 0 (first derivative)\n",
    "        [1.0, 1],  # f'(1) = 0 (first derivative)\n",
    "    ])\n",
    "]\n",
    "\n",
    "constraints_y = [\n",
    "    jnp.array([\n",
    "        [0.0, 0.0, 0.0, 0.0],  # All constraints = 0\n",
    "    ])\n",
    "]\n",
    "\n",
    "print(\"Constraints:\")\n",
    "print(\"  f(0) = 0   (boundary value)\")\n",
    "print(\"  f(1) = 0   (boundary value)\")\n",
    "print(\"  f'(0) = 0  (zero slope)\")\n",
    "print(\"  f'(1) = 0  (zero slope)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-deriv-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with derivative constraints\n",
    "# Use higher degree k for derivative constraints\n",
    "model_deriv, state_deriv = eqx.nn.make_with_state(AdaptKANJax)(\n",
    "    width=[1, 1],\n",
    "    num_grid_intervals=9,\n",
    "    k=9,                              # Higher degree needed for derivative constraints\n",
    "    basis_type='chebyshev',\n",
    "    initialization_range=[0.0, 1.0],\n",
    "    constraints_in=constraints_in,\n",
    "    constraints_y=constraints_y,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Layer 0 has_constraints: {model_deriv.layers[0].has_constraints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-deriv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with animations!\n",
    "model_deriv, state_deriv, results_deriv = fit(\n",
    "    model_deriv,\n",
    "    state_deriv,\n",
    "    train_data={\"X\": X_train, \"y\": y_train},\n",
    "    test_data={\"X\": X_test, \"y\": y_test},\n",
    "    loss_fn=mse_loss,\n",
    "    opt=\"Adam\",\n",
    "    learning_rate=0.1,\n",
    "    steps=500,\n",
    "    log_freq=50,\n",
    "    # Animation settings\n",
    "    snapshot_every=10,                # Capture frame every 10 steps\n",
    "    save_name=\"deriv_constraints\",\n",
    "    save_path=\"results/animations\",\n",
    "    fps=15,\n",
    ")\n",
    "\n",
    "print(f\"\\nAnimation saved to results/animations/deriv_constraints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-deriv-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results with derivative constraints\n",
    "y_learned_deriv, _ = model_deriv(x_plot, state_deriv)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(x_plot, y_target, 'b-', lw=2, label='Target: sin²(πx)')\n",
    "ax.plot(x_plot, y_learned_deriv, 'g--', lw=2, label='Learned')\n",
    "\n",
    "# Mark constraint points\n",
    "ax.scatter([0, 1], [0, 0], color='red', s=100, zorder=5, marker='o', label='Value constraints')\n",
    "\n",
    "# Mark derivative constraints with horizontal lines (slope=0)\n",
    "for x_c in [0.0, 1.0]:\n",
    "    ax.plot([x_c-0.05, x_c+0.05], [0, 0], 'orange', lw=3, zorder=4)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.set_title('Derivative Constraints: f(0)=f(1)=0, f\\'(0)=f\\'(1)=0')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-deriv-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize layer with constraint markers\n",
    "# Red dots = value constraints, Orange lines = derivative constraints\n",
    "fig = plot_layer(model_deriv, state_deriv, layer_index=0, \n",
    "                 title=\"Layer with Derivative Constraints\",\n",
    "                 tangent_length=0.2,\n",
    "                 square_size=2.5,\n",
    "                 fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3-markdown",
   "metadata": {},
   "source": [
    "## 3. Constraints with Domain Adaptation\n",
    "\n",
    "Constraints are maintained even when the domain expands. Let's train with data outside the initial domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ood-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data OUTSIDE the initial [0, 1] domain\n",
    "key = jax.random.PRNGKey(123)\n",
    "X_train_ood = jax.random.uniform(key, (300, 1), minval=-0.5, maxval=1.5)\n",
    "y_train_ood = target_fn(X_train_ood)\n",
    "\n",
    "print(f\"Training data range: [{float(X_train_ood.min()):.2f}, {float(X_train_ood.max()):.2f}]\")\n",
    "print(\"(This extends beyond initial domain [0, 1])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-adapt-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model that will adapt its domain\n",
    "model_adapt, state_adapt = eqx.nn.make_with_state(AdaptKANJax)(\n",
    "    width=[1, 1],\n",
    "    num_grid_intervals=9,\n",
    "    k=9,\n",
    "    basis_type='chebyshev',\n",
    "    initialization_range=[0.0, 1.0],\n",
    "    constraints_in=constraints_in,     # Same derivative constraints\n",
    "    constraints_y=constraints_y,\n",
    "    stretch_threshold=0.05,            # Expand if >5% data is out-of-domain\n",
    "    prune_patience=3,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "layer = model_adapt.layers[0]\n",
    "a_init = float(state_adapt.get(layer.a)[0])\n",
    "b_init = float(state_adapt.get(layer.b)[0])\n",
    "print(f\"Initial domain: [{a_init:.2f}, {b_init:.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-adapt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with domain adaptation\n",
    "model_adapt, state_adapt, results_adapt = fit(\n",
    "    model_adapt,\n",
    "    state_adapt,\n",
    "    train_data={\"X\": X_train_ood, \"y\": y_train_ood},\n",
    "    loss_fn=mse_loss,\n",
    "    opt=\"Adam\",\n",
    "    learning_rate=0.1,\n",
    "    steps=500,\n",
    "    log_freq=50,\n",
    "    adapt_model=True,                  # Enable domain adaptation\n",
    "    # Animation settings\n",
    "    snapshot_every=10,\n",
    "    save_name=\"adapt_constraints\",\n",
    "    save_path=\"results/animations\",\n",
    "    fps=15,\n",
    ")\n",
    "\n",
    "# Check final domain\n",
    "layer = model_adapt.layers[0]\n",
    "a_final = float(state_adapt.get(layer.a)[0])\n",
    "b_final = float(state_adapt.get(layer.b)[0])\n",
    "print(f\"\\nFinal domain: [{a_final:.2f}, {b_final:.2f}]\")\n",
    "print(f\"Domain adapted: {(a_final, b_final) != (a_init, b_init)}\")\n",
    "print(f\"Adaptation events: {results_adapt['adapted_epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-adapt-constraints",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Verify constraints are STILL satisfied after domain adaptation!\n",
    "x_test_constraints = jnp.array([[0.0], [1.0]])\n",
    "y_pred, _ = model_adapt(x_test_constraints, state_adapt)\n",
    "\n",
    "print(\"Constraints after domain adaptation:\")\n",
    "print(f\"  f(0) = {float(y_pred[0, 0]):.6f} (target: 0)\")\n",
    "print(f\"  f(1) = {float(y_pred[1, 0]):.6f} (target: 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-adapt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with expanded domain\n",
    "x_plot_wide = jnp.linspace(a_final - 0.1, b_final + 0.1, 300).reshape(-1, 1)\n",
    "y_learned_adapt, _ = model_adapt(x_plot_wide, state_adapt)\n",
    "y_target_wide = target_fn(x_plot_wide)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(x_plot_wide, y_target_wide, 'b-', lw=2, label='Target: sin²(πx)')\n",
    "ax.plot(x_plot_wide, y_learned_adapt, 'g--', lw=2, label='Learned')\n",
    "\n",
    "# Mark constraint points\n",
    "ax.scatter([0, 1], [0, 0], color='red', s=100, zorder=5, label='Constraints')\n",
    "\n",
    "# Mark original domain\n",
    "ax.axvspan(0, 1, alpha=0.1, color='yellow', label='Initial domain')\n",
    "\n",
    "# Mark training data range  \n",
    "ax.axvline(x=-0.5, color='gray', linestyle=':', alpha=0.5, label='Training range')\n",
    "ax.axvline(x=1.5, color='gray', linestyle=':', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.set_title(f'Constraints Maintained After Domain Adaptation\\nDomain: [{a_final:.2f}, {b_final:.2f}]')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-adapt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the adapted layer\n",
    "fig = plot_layer(model_adapt, state_adapt, layer_index=0,\n",
    "                 title=f\"Adapted Layer (domain: [{a_final:.2f}, {b_final:.2f}])\",\n",
    "                 tangent_length=0.15,\n",
    "                 square_size=2.5,\n",
    "                 fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Layer Networks with Constraints\n",
    "\n",
    "You can apply constraints to specific layers in a deeper network. Use `None` for layers without constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multilayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-layer network: constrain only the first layer\n",
    "constraints_in_multi = [\n",
    "    jnp.array([[0.0, 0], [1.0, 0]]),  # Layer 0: constrained\n",
    "    None,                               # Layer 1: no constraints\n",
    "]\n",
    "\n",
    "constraints_y_multi = [\n",
    "    jnp.array([[0.0, 0.0], [0.0, 0.0]]),  # Layer 0: 2 outputs, 2 constraints each\n",
    "    None,\n",
    "]\n",
    "\n",
    "model_multi, state_multi = eqx.nn.make_with_state(AdaptKANJax)(\n",
    "    width=[1, 2, 1],                   # 1 -> 2 -> 1\n",
    "    num_grid_intervals=7,\n",
    "    k=7,\n",
    "    basis_type='chebyshev',\n",
    "    initialization_range=[0.0, 1.0],\n",
    "    constraints_in=constraints_in_multi,\n",
    "    constraints_y=constraints_y_multi,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Model width: {model_multi.width}\")\n",
    "print(f\"Layer 0 has_constraints: {model_multi.layers[0].has_constraints}\")\n",
    "print(f\"Layer 1 has_constraints: {model_multi.layers[1].has_constraints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-multi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the multi-layer model\n",
    "model_multi, state_multi, results_multi = fit(\n",
    "    model_multi,\n",
    "    state_multi,\n",
    "    train_data={\"X\": X_train, \"y\": y_train},\n",
    "    test_data={\"X\": X_test, \"y\": y_test},\n",
    "    loss_fn=mse_loss,\n",
    "    opt=\"Adam\",\n",
    "    learning_rate=0.1,\n",
    "    steps=500,\n",
    "    log_freq=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-multi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all layers\n",
    "plot_model(model_multi, state_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Constraint Format\n",
    "```python\n",
    "# constraints_in: list of arrays per layer\n",
    "# Each array: (n_constraints, 2) where columns are [x, derivative_order]\n",
    "#   derivative_order: 0=value, 1=first derivative, 2=second derivative, etc.\n",
    "\n",
    "# constraints_y: list of arrays per layer  \n",
    "# Each array: (out_dim, n_constraints) with target values\n",
    "# Use None for layers without constraints\n",
    "```\n",
    "\n",
    "### Key Points\n",
    "1. Constraints require `basis_type='chebyshev'`\n",
    "2. Use higher polynomial degree `k` for derivative constraints\n",
    "3. Constraints are satisfied **exactly** throughout training\n",
    "4. Constraints are maintained during domain adaptation\n",
    "5. Use `snapshot_every` in `fit()` to create training animations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
